# 研究比較

### A Review Of 3D Human Pose Estimation From 2D Images 2D画像からの3D人物ポーズ推定のレビュー
人間のポーズ推定タスクは、画像を入力とし、あらかじめ定義された体の関節と、関節間の疎な接続を表す位置のセット（ボディパーツ）を抽出するものである。 ポーズは、単一または複数のフレームから、単一（単眼）または多眼（ステレオ）のセットアップで、シーン内の単一の人物または複数の人物に対して推定することができます。本研究では、古典的なアプローチと深層学習に基づく3Dポーズ推定アプローチの概要を説明します。また、関連する評価指標、ポーズパラメータ化、ボディモデル、3D人物ポーズデータセットを紹介する。最後に、最先端のポーズ推定結果をレビューし、未解決の問題を簡単に議論し、可能な将来の研究の方向性を提案する。
* November 2020  
* 11th International Conference and Exhibition on 3D Body Scanning and Processing Technologies
* https://www.researchgate.net/publication/346413419_A_Review_of_3D_Human_Pose_Estimation_from_2D_Images

### Deep Learning-Based Human Pose Estimation: A Survey 深層学習を用いた人間の姿勢の推定。調査
人間の姿勢推定は、画像や動画などの入力データから、人体のパーツの位置を特定し、人体表現（ボディスケルトンなど）を構築することを目的としています。これは、過去10年間に注目を集め、人間とコンピュータのインタラクション、動作解析、拡張現実感、仮想現実感など、幅広い用途に利用されています。最近開発された深層学習を用いたソリューションは，人間の姿勢推定において高い性能を達成しているが，不十分な学習データ，深度の曖昧さ，オクルージョンなどによる課題が残っている．この調査論文の目的は、2Dおよび3Dの両方のポーズ推定のための最近の深層学習ベースのソリューションを、入力データと推論手順に基づいて体系的に分析・比較することで、包括的なレビューを提供することです。この調査では、2014年以降の240以上の研究論文が対象となっています。さらに、2Dおよび3Dの人間のポーズ推定データセットと評価指標も含まれています。一般的なデータセットにおけるレビュー済みの手法の定量的な性能比較をまとめ、議論しています。最後に、関連する課題、アプリケーション、および将来の研究の方向性について結論付けています。
* Dec 2020 
* 
* https://paperswithcode.com/paper/deep-learning-based-human-pose-estimation-a

# pose推定

### VIBE- Video Inference for Human Body Pose and Shape Estimation VIBE-ビデオ 人体の姿勢と形状を推定するための推論
人間の動きは、行動を理解するための基本です。単一画像の 3D ポーズと形状推定の進歩にもかかわらず、トレーニング用のグラウンド トゥルース 3D モーション データが不足しているため、既存のビデオ ベースの最先端の方法では正確で自然なモーション シーケンスを生成できません。 この問題に対処するために、既存の大規模なモーション キャプチャ データセット (AMASS) を、ペアになっていない、野生の 2D キーポイント注釈とともに利用する、体のポーズと形状の推定 (VIBE) のビデオ推論を提案します。私たちの重要な目新しさは、AMASS を活用して実際の人間の動きと、一時的な姿勢と形状の回帰ネットワークによって生成された動きとを区別する敵対的学習フレームワークです。時間的ネットワーク アーキテクチャを定義し、シーケンス レベルでの敵対的トレーニングが、野生のグラウンド トゥルース 3D ラベルなしで運動学的にもっともらしいモーション シーケンスを生成することを示します。私たちは、動きの重要性を分析するために広範な実験を行い、困難な 3D 姿勢推定データセットに対する VIBE の有効性を実証し、最先端のパフォーマンスを実現します。
* CVPR 2020
* https://paperswithcode.com/paper/vibe-video-inference-for-human-body-pose-and#

# 3Dモデル推定

### DenseBody- Directly Regressing Dense 3D Human Pose and Shape From a Single Color Image DenseBody-1枚のカラー画像から緻密な3次元の人間の姿勢と形状を直接回帰する技術
2次元画像から3次元の人体の形状と姿勢を復元することは、人体が非常に複雑で柔軟であることと、3次元のラベル付きデータが比較的少ないことから、困難な課題となっています。このような問題に対処する従来の手法は、より多くの2Dラベルを利用するために問題を複数のサブタスクに分解して、身体部位のセグメンテーション、2D/3Dジョイント、シルエットマスクなどの中間結果を予測することに依存しています。これまでの研究では、人体を表現するために、パラメトリックな体型モデルを取り入れ、低次元空間でパラメータを予測していました。本論文では、Convolutional Neural Network(CNN)を用いて、1枚のカラー画像から人間の3次元メッシュを直接回帰することを提案する。本手法では，エンコーダ・デコーダ型のニューラルネットワークを用いて，人間の3次元形状と姿勢を効率的に表現する．提案手法は、Human3.6M、SURREAL、UP-3Dなどの複数の3D人体データセットにおいて、最先端の性能を達成し、さらに高速に動作する。
* Mar 2019
* DenseBody
* https://paperswithcode.com/paper/densebody-directly-regressing-dense-3d-human

### DensePose- Dense Human Pose Estimation In The Wild DensePose: 自然な状態での高密度人体ポーズ推定
本研究では，RGB画像と人体の表面ベースの表現との間の密な対応関係を確立する．これは，密な人体ポーズ推定と呼ばれるタスクである．まず、効率的なアノテーション・パイプラインを導入することで、COCOデータセットに含まれる5万人の人物の密な対応関係を収集します。次に、このデータセットを用いて、背景、オクルージョン、スケールの変化があっても、密な対応関係を実現するCNNベースのシステムを訓練する。さらに、欠損しているグランドトゥルース値を補うことができる「インペインティング」ネットワークを学習することで、学習セットの有効性を向上させ、過去に達成可能だった最良の結果と比較して明らかな改善を報告している。また、完全畳み込みネットワークとリージョンベースのモデルを試したところ、後者の方が優れていることが分かりました。さらに、カスケード接続によって精度を向上させ、リアルタイムで高精度な結果を得ることができました。補足資料や動画はプロジェクトページ（http://densepose.org）に掲載されています。
* CVPR 2018
* DensePose
* https://paperswithcode.com/paper/densepose-dense-human-pose-estimation-in-the

### FrankMocap: Fast Monocular 3D Hand and Body Motion Capture by Regression and Integration FrankMocap: 回帰と統合による高速な単眼3D手と体のモーションキャプチャー
人間の動きの本質的なニュアンスは、体の動きと手のジェスチャーの組み合わせとして伝えられることが多いが、既存の単眼モーションキャプチャのアプローチは、手の部分を無視した体の動きだけのキャプチャか、体の動きを考慮しない手の動きだけのキャプチャのどちらかに焦点を当てていることがほとんどである。本論文では、FrankMocapを紹介します。FrankMocapは、従来の手法よりも高速（9.5 fps）かつ高精度に、実世界の単眼入力から手と体の両方の3Dモーションを推定できるモーションキャプチャシステムです。本手法は、ほぼリアルタイム（9.5fps）で動作し、3Dボディとハンドのモーションキャプチャー出力を統一されたパラメトリックモデル構造として生成します。私たちの手法は、チャレンジングな野生の単眼動画から、3Dボディとハンドモーションを同時にキャプチャすることを目的としています。FrankMocapを構築するために、私たちは、全身パラメトリックモデル（SMPL-X）の手の部分を取ることによって、最先端の単眼3D「手」のモーションキャプチャ方法を構築しました。手のモーションキャプチャーの出力は、単眼のボディモーションキャプチャーの出力と効率的に統合され、統一されたパラメトリックモデル構造の中で全身のモーション結果を生成することができます。我々のハンドモーションキャプチャーシステムの最先端の性能を公開ベンチマークで実証し、ライブデモシナリオを含む様々な困難な実世界のシーンで、我々の全身モーションキャプチャー結果の高品質を示します。
* Aug 2020
* FrankMocap
* https://paperswithcode.com/paper/frankmocap-fast-monocular-3d-hand-and-body

# poseと3Dモデル推定

### I2L-MeshNet: Image-to-Lixel Prediction Network for Accurate 3D Human Pose and Mesh Estimation from a Single RGB Image I2L-MeshNet: 1枚のRGB画像から人間の3Dポーズとメッシュを正確に推定するImage-to-Lixel Prediction Network
これまでの画像ベースの3次元人物姿勢・メッシュ推定手法の多くは、入力画像から人物メッシュモデルのパラメータを推定するものでした。しかし、入力画像からパラメータを直接回帰することは、入力画像のピクセル間の空間的な関係を壊してしまうため、非常に非線形なマッピングとなります。また，予測の不確実性をモデル化することができないため，学習が困難になる可能性があります．このような問題を解決するために，我々は画像からリクセル（線＋画素）への予測ネットワークであるI2L-MeshNetを提案する．提案するI2L-MeshNetは、パラメータを直接回帰するのではなく、各メッシュ頂点座標の1次元ヒートマップ上で、リクセルごとの尤度を予測する。リクセルベースの1Dヒートマップは、入力画像の空間的な関係を保持し、予測の不確実性をモデル化する。我々は，画像からリクセルへの予測の利点を実証し，提案するI2L-MeshNetが従来の手法よりも優れていることを示した．コードは公開されています。https://github.com/mks0601/I2L-MeshNet_RELEASE。
* ECCV 2020
* I2L-MeshNet
* https://paperswithcode.com/paper/i2l-meshnet-image-to-lixel-prediction-network-1

### Exemplar Fine-Tuning for 3D Human Model Fitting Towards In-the-Wild 3D Human Pose Estimation 3次元人物モデルのフィッティングにおけるExemplar Fine-Tuningによる実世界での3次元人物ポーズの推定
本研究では、2Dのキーポイントアノテーションを持つ人物の周りを切り取ったRGBの入力画像に、3Dパラメトリック人体モデルをフィットさせる新しい手法であるExemplar Fine-Tuning (EFT)を提案する。SMPLifyに代表される既存のパラメトリック人体モデル適合手法は、人間の姿勢に関する "ビューアグノスティック "な事前情報に依存して、妥当な3次元姿勢空間での出力を保証しているが、EFTは、完全に訓練された3次元姿勢レグレッサーを利用して、特定の2次元入力観測から得られる姿勢の事前情報を利用する。我々のEFTとSMPLifyを徹底的に比較し、EFTが同じ入力に対してより信頼性の高い、正確な3Dフィッティング出力を生成することを実証しました。特に、我々のEFTを用いて、COCOやMPIIなどの大規模なin-the-wildの2Dキーポイントデータセットを、もっともらしく説得力のある3Dポーズフィッティング出力で補強しました。EFTによって擬似的に得られた3Dポーズデータは、Human3.6Mのような人間の3Dポーズデータを使わなくても、標準的な屋外ベンチマーク（3DPW）において、従来の最先端技術を凌駕する強力な3Dポーズ推定量をスーパーバイズできることを実証した。我々のコードとデータは、https://github.com/facebookresearch/eft。
* Apr 2020 
* Exemplar Fine-Tuning (EFT)
* https://paperswithcode.com/paper/exemplar-fine-tuning-for-3d-human-pose

### Learning to Reconstruct 3D Human Pose and Shape via Model-fitting in the Loop ループ内でのモデル・フィッティングによる人間の3次元ポーズと形状の再構築の学習
モデルベースの人間のポーズ推定は、現在2つの異なるパラダイムでアプローチされています。最適化ベースの手法は、パラメトリックなボディモデルを2次元の観測データに反復的に適合させることで、画像とモデルの正確な位置合わせを実現するが、時間がかかり、初期化に敏感な場合が多い。対照的に、深層ネットワークを用いてピクセルからモデルパラメータを直接推定する回帰ベースの手法は、膨大な量の監視を必要とする一方で、ピクセル精度ではないが妥当な結果を提供する傾向がある。本研究では、どちらのアプローチが優れているかを調査するのではなく、2つのパラダイムが強力なコラボレーションを形成できるということを重要な洞察としています。ネットワークから直接回帰された妥当な推定値は、反復最適化を初期化することができ、フィッティングをより速く、より正確にすることができます。同様に、反復最適化によるピクセルの正確なフィットは、ネットワークの強力な監視として機能します。これが私たちの提案するアプローチSPIN（SMPL oPtimization IN the loop）の核心です。ディープネットワークは、トレーニングループ内でボディモデルを2D関節にフィットさせる反復最適化ルーチンを初期化し、フィットした推定値はその後ネットワークのスーパーバイズに使用されます。ネットワークの推定値が高ければ、最適化をより良い解決策に導くことができ、最適化の適合度が高ければ、ネットワークの監視をより適切に行うことができるため、我々のアプローチは本質的に自己改善的である。我々は、3Dグランドトゥルースが少ない、あるいは入手できない様々な環境において、我々のアプローチの有効性を実証し、最先端のモデルベースのポーズ推定アプローチを一貫して大幅に凌駕しています。このプロジェクトのウェブサイトには、ビデオ、結果、コードが掲載されており、https://seas.upenn.edu/~nkolot/projects/spinにあります。
* ICCV 2019 
* SPIN（SMPL oPtimization IN the loop）
* https://paperswithcode.com/paper/learning-to-reconstruct-3d-human-pose-and

# 顔系

### Learning an Animatable Detailed 3D Face Model from In-The-Wild Images 野生の画像からアニメーション可能な詳細な3D顔モデルを学習する
現在の単眼3D顔再構成法は、微細な幾何学的ディテールを復元できるものの、いくつかの限界があります。いくつかの手法では、表情によるしわの変化がモデル化されていないため、現実的なアニメーションができない顔が生成されます。また、高品質の顔スキャンを用いて学習する手法もありますが、一般的な画像にはうまく対応できません。本研究では、アニメーションが可能な詳細なモデルと、詳細な3次元顔面回帰器を、野生の画像から共同で学習する初めての手法を提案する。この手法では、形状の詳細と表情との関係を回復する。我々のDECA（Detailed Expression Capture and Animation）モデルは、人特有のディテールパラメータと一般的な表情パラメータからなる低次元の潜在表現から、UVディスプレイスメントマップをロバストに生成するように学習されており、一方のリグレッサーは、1枚の画像からディテール、形状、アルベド、表情、ポーズ、照明パラメータを予測するように学習されています。本研究では、人に固有のディテールと表情に依存するしわを分離するために、新しいディテール-コンシステンシー損失を導入しました。この分離により、人物固有のディテールはそのままに、表情パラメータを制御することで、リアルな人物固有のシワを合成することができます。DECAは、2つのベンチマークにおいて、最先端の形状再構成精度を達成しました。また、実世界のデータを用いた定性的な結果では、DELAのロバスト性と、人物と表情に依存するディテールを切り離す能力が実証され、再構成された顔のアニメーションが可能になりました。このモデルとコードは、https://github.com/YadiraF/DECA で公開されています。
* https://paperswithcode.com/paper/learning-an-animatable-detailed-3d-face-model

### Towards Fast, Accurate and Stable 3D Dense Face Alignment 高速・高精度・安定した3D Dense Face Alignmentを目指して
既存の3次元顔照合法は、主に精度に重点が置かれているため、実用化の範囲が限られています。本論文では、3DDFA-V2と名付けられた新しい回帰フレームワークを提案する。まず，軽量バックボーンをベースに，メタジョイント最適化戦略を提案し，小さな3DMMパラメータのセットを動的に回帰させることで，速度と精度を同時に大幅に向上させる。さらに、動画での安定性を向上させるために、1枚の静止画を面内および面外の顔の動きを取り入れた短い動画に変換する仮想合成法を提案します。高い精度と安定性を前提に、3DDFA-V2はシングルCPUコアで50fps以上の速度で動作し、他の最先端の重いモデルを同時に凌駕します。いくつかの困難なデータセットを用いた実験により、本手法の効率性が検証されています。学習済みのモデルとコードは、https://github.com/cleardusk/3DDFA_V2。
* https://paperswithcode.com/paper/towards-fast-accurate-and-stable-3d-dense-1

### MVF-Net: Multi-View 3D Face Morphable Model Regression マルチビュー3Dフェイスモルファブルモデル回帰
我々は、複数のビューの顔画像セットから人間の顔の3Dジオメトリを復元するという問題に取り組んでいます。最近の研究では、3D Morphable Model (3DMM)を用いた顔の再構成に目覚ましい進歩が見られますが、その設定はほとんどが単一のビューに限定されています。これは、3次元的な制約がないため、解決できない曖昧さが生じるというものです。本論文では、3DMMに基づく形状復元を、多視点の顔画像を入力とする別の設定で検討します。マルチビューの入力から3DMMのパラメータを回帰させるために、エンドツーエンドで学習可能なConvolutional Neural Network（CNN）を用いた新しいアプローチを提案します。マルチビューの幾何学的制約は、異なるビュー間の密な対応関係を確立することで、自己教師付きのビュー・アライメント・ロスを利用してネットワークに組み込まれる。このビュー・アライメント・ロスの主な要素は、微分可能な高密度オプティカル・フロー推定器であり、入力ビューと別の入力ビューからの合成レンダリングとの間のアライメント・エラーを逆伝播させることができる。ビューの位置合わせ損失を最小限に抑えることで、より良い3D形状を復元し、あるビューから別のビューへの合成レンダリングが、対象となる画像とより良い位置関係になるようにすることができます。大規模な実験により、提案手法が他の3DMM手法よりも優れていることが実証された。
* https://paperswithcode.com/paper/mvf-net-multi-view-3d-face-morphable-model
